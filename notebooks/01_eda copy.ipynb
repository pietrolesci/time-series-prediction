{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful articles:\n",
    "\n",
    "- [The short-term predictability of returns in order book markets: A deep learning perspective](https://pdf.sciencedirectassets.com/271676/1-s2.0-S0169207024X00047/1-s2.0-S0169207024000062/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjELD//////////wEaCXVzLWVhc3QtMSJIMEYCIQColRlLpV+nTPDAZMPx3XCiAZsSXspseHKIZOEEWpVGWAIhAKkUipMTCXHCJfJCjU8EM7pmx4Ybi3VhcbIM4YSswpI2KrIFCEkQBRoMMDU5MDAzNTQ2ODY1IgzHaUBW4qumlsAA57gqjwV6ZDJwSLFW1etGpf4ilzHo2DKQCKABKp87sR9MiflLHAIPClTwC8OQgLVH3O0EVdjk/djOFe2lJXL2fWdKId+JdPeb34mtmFPBNoa2e234zcc42CaZZ+2nuYLykKu7FgFZgMsgL7uy8WiJV7JP0fD5PjUiRBnINM/IhVDoMz/2HsM3PDAt6U8swxyOE6GS3fopMz8QtyaxOd1b4nnje4gMfSFMdhAOQ0F1jJEhEKGScfVH7UN/7Cwy/Ak6lRIy3dbAZFVRYg/2MiInqKpLNCCmmOS6mS/SWlLkKKPMUotK5lGLb3hIfsefslmaZNHbcgtiIZO/ItglZHBjZ9I7TIgkOvftjTiTlv4t1xb/mG3hb4oU8tI9hd1097vcz3Xskt7CVkPCaCbgUfnbHNQiMRTY/NEaWiH9EHikLLP/9vgaGxUrtI+MedNcdf+ii0E/kS/3EkEf8BH2R2cHPIMVdftjIDDYjff3mHZCQwkHnvU47DmSSyn8dF46i/FZsqrgp98h4N2nuPTe0C515bxlu3eadad+hV6mFPMYNT3kuDdCCzRUdBMKL7fZ0fNMcb0/TJ66xLWuPs+2fMmH3dHiGcW4j87GjgDPUCiTzMHw9mzffxsPTmDMS1Mdbwyoy6yA6bfQynB8ZqXXVyFNXu5Lz4Sp58ckgBws6juFfC6yuR4WjDgs85WNhBykXQrqZaf9YGRobG2J/1bLHdAhnSR7J2fJdNhdPjEk2Xp4t+FG5AoOhY8Elo31BEU8SVTTlRr+mOHlE8k9KFh5Np0fubRd9Vj91yz5idVlmngyx4mu1P1jRHtNvsU9EVjmV76/xgmRhM8e055LYnnLrLfsoN0ery0OfLaEhuy2ky9P8ZUzBx/VMJab6LkGOrAB1vrP6dvfwKdo27s1ZH0+hStVJ5/j5/jV4nsd3wJRec0dLaVe+TXhRtWQZpjOH0/W9qyuApgwhafaVNR3sG8uikmoXpNl/qcydrjQ735T5jXFPv521VXYdFkeOpZWeefELBc0sGd7Gu/9rSWBjZw1TAMT4fnftmHPJ5WKg3iLgypbS59hEdLw45pAZgkfsFaogTHvaiH+fcTfw60sI+gkpR+beaf75bR8f+bJJ44bf1g%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20241117T161753Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY2CNS7ALU/20241117/us-east-1/s3/aws4_request&X-Amz-Signature=4d308461505864efa28d74d5d860247b74c92d1dfa129589c0978d272be2bd2a&hash=f6b345b3c06112ac6875d095f3fedc7fb20f4d7afff105ec766e34f19d40ef0d&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0169207024000062&tid=spdf-a4179bf3-fe28-48dc-a3a1-78e08aec5a61&sid=161508629856824cf868caf8f49d69b18751gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1d045d0a57565f565f5c51&rr=8e4108934a9e779f&cc=gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as pn\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3497666, 62)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data more easily accessible\n",
    "# Read L2 data\n",
    "# df = pl.read_csv(\"data/data.csv.gz\")\n",
    "df = (\n",
    "    pl.read_parquet(\"data/data.parquet\")\n",
    "    # Assuming that order reflects time\n",
    "    .with_row_index(name=\"time\").with_columns(pl.col(\"time\").cast(pl.Int64))\n",
    "    # # Fill nulls with 0\n",
    "    # .with_columns((cs.contains(\"Rate\") | cs.contains(\"Size\")).fill_null(0))\n",
    ")\n",
    "\n",
    "cols = [\"time\", \"y\"]\n",
    "\n",
    "# Reorder cols\n",
    "order_book_feat = []\n",
    "for side in [\"ask\", \"bid\"]:\n",
    "    for i in range(15):\n",
    "        order_book_feat += [f\"{side}Rate{i}\", f\"{side}Size{i}\"]\n",
    "\n",
    "df = df.select(cols + order_book_feat)\n",
    "\n",
    "# check no nan (there are nulls though, as expected)\n",
    "assert df.with_columns(pl.all().is_nan()).sum_horizontal().sum() == 0\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tick_size=0.5\n"
     ]
    }
   ],
   "source": [
    "# compute tick size\n",
    "exps = [\n",
    "    pl.col(f\"{side}Rate{i}\") - pl.col(f\"{side}Rate{i-1}\")\n",
    "    for i in range(1, 15)\n",
    "    for side in [\"ask\", \"bid\"]\n",
    "]\n",
    "\n",
    "tick_size = (\n",
    "    # select prices\n",
    "    df.select(cs.contains(\"Rate\"))\n",
    "    # run differences wrt previous level\n",
    "    .with_columns(*exps)\n",
    "    # get absolute values\n",
    "    .with_columns(pl.all().abs())\n",
    "    # get the minimum per row and then overall\n",
    "    .min_horizontal().min()\n",
    ")\n",
    "print(f\"{tick_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3_497_666, 62)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>y</th><th>askRate0</th><th>askSize0</th><th>askRate1</th><th>askSize1</th><th>askRate2</th><th>askSize2</th><th>askRate3</th><th>askSize3</th><th>askRate4</th><th>askSize4</th><th>askRate5</th><th>askSize5</th><th>askRate6</th><th>askSize6</th><th>askRate7</th><th>askSize7</th><th>askRate8</th><th>askSize8</th><th>askRate9</th><th>askSize9</th><th>askRate10</th><th>askSize10</th><th>askRate11</th><th>askSize11</th><th>askRate12</th><th>askSize12</th><th>askRate13</th><th>askSize13</th><th>askRate14</th><th>askSize14</th><th>bidRate0</th><th>bidSize0</th><th>bidRate1</th><th>bidSize1</th><th>bidRate2</th><th>bidSize2</th><th>bidRate3</th><th>bidSize3</th><th>bidRate4</th><th>bidSize4</th><th>bidRate5</th><th>bidSize5</th><th>bidRate6</th><th>bidSize6</th><th>bidRate7</th><th>bidSize7</th><th>bidRate8</th><th>bidSize8</th><th>bidRate9</th><th>bidSize9</th><th>bidRate10</th><th>bidSize10</th><th>bidRate11</th><th>bidSize11</th><th>bidRate12</th><th>bidSize12</th><th>bidRate13</th><th>bidSize13</th><th>bidRate14</th><th>bidSize14</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>-0.5</td><td>1619.5</td><td>1.0</td><td>1620.0</td><td>10.0</td><td>1621.0</td><td>24.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1615.0</td><td>7.0</td><td>1614.0</td><td>10.0</td><td>1613.0</td><td>1.0</td><td>1612.0</td><td>10.0</td><td>1611.0</td><td>20.0</td><td>1610.0</td><td>3.0</td><td>1607.0</td><td>20.0</td><td>1606.0</td><td>27.0</td><td>1605.0</td><td>11.0</td><td>1604.0</td><td>14.0</td><td>1603.0</td><td>35.0</td><td>1602.0</td><td>10.0</td><td>1601.5</td><td>1.0</td><td>1601.0</td><td>10.0</td><td>1600.0</td><td>13.0</td></tr><tr><td>1</td><td>-0.5</td><td>1619.5</td><td>1.0</td><td>1620.0</td><td>10.0</td><td>1621.0</td><td>24.0</td><td>1621.5</td><td>5.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1615.0</td><td>7.0</td><td>1614.0</td><td>10.0</td><td>1613.0</td><td>1.0</td><td>1612.0</td><td>10.0</td><td>1611.0</td><td>20.0</td><td>1610.0</td><td>3.0</td><td>1607.0</td><td>20.0</td><td>1606.0</td><td>27.0</td><td>1605.0</td><td>11.0</td><td>1604.0</td><td>14.0</td><td>1603.0</td><td>35.0</td><td>1602.0</td><td>10.0</td><td>1601.5</td><td>1.0</td><td>1601.0</td><td>10.0</td><td>1600.0</td><td>13.0</td></tr><tr><td>2</td><td>-0.5</td><td>1619.5</td><td>1.0</td><td>1620.0</td><td>10.0</td><td>1621.0</td><td>24.0</td><td>1621.5</td><td>5.0</td><td>1622.0</td><td>2.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1615.0</td><td>7.0</td><td>1614.0</td><td>10.0</td><td>1613.0</td><td>1.0</td><td>1612.0</td><td>10.0</td><td>1611.0</td><td>20.0</td><td>1610.0</td><td>3.0</td><td>1607.0</td><td>20.0</td><td>1606.0</td><td>27.0</td><td>1605.0</td><td>11.0</td><td>1604.0</td><td>14.0</td><td>1603.0</td><td>35.0</td><td>1602.0</td><td>10.0</td><td>1601.5</td><td>1.0</td><td>1601.0</td><td>10.0</td><td>1600.0</td><td>13.0</td></tr><tr><td>3</td><td>-0.5</td><td>1619.5</td><td>1.0</td><td>1620.0</td><td>10.0</td><td>1621.0</td><td>24.0</td><td>1621.5</td><td>5.0</td><td>1622.0</td><td>22.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1615.0</td><td>7.0</td><td>1614.0</td><td>10.0</td><td>1613.0</td><td>1.0</td><td>1612.0</td><td>10.0</td><td>1611.0</td><td>20.0</td><td>1610.0</td><td>3.0</td><td>1607.0</td><td>20.0</td><td>1606.0</td><td>27.0</td><td>1605.0</td><td>11.0</td><td>1604.0</td><td>14.0</td><td>1603.0</td><td>35.0</td><td>1602.0</td><td>10.0</td><td>1601.5</td><td>1.0</td><td>1601.0</td><td>10.0</td><td>1600.0</td><td>13.0</td></tr><tr><td>4</td><td>-0.5</td><td>1619.5</td><td>1.0</td><td>1620.0</td><td>10.0</td><td>1621.0</td><td>24.0</td><td>1621.5</td><td>5.0</td><td>1622.0</td><td>32.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1615.0</td><td>7.0</td><td>1614.0</td><td>10.0</td><td>1613.0</td><td>1.0</td><td>1612.0</td><td>10.0</td><td>1611.0</td><td>20.0</td><td>1610.0</td><td>3.0</td><td>1607.0</td><td>20.0</td><td>1606.0</td><td>27.0</td><td>1605.0</td><td>11.0</td><td>1604.0</td><td>14.0</td><td>1603.0</td><td>35.0</td><td>1602.0</td><td>10.0</td><td>1601.5</td><td>1.0</td><td>1601.0</td><td>10.0</td><td>1600.0</td><td>13.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>3497661</td><td>0.0</td><td>1576.0</td><td>3.0</td><td>1576.5</td><td>1.0</td><td>1577.0</td><td>10.0</td><td>1577.5</td><td>1.0</td><td>1578.0</td><td>3.0</td><td>1579.0</td><td>1.0</td><td>1579.5</td><td>8.0</td><td>1581.5</td><td>10.0</td><td>1582.0</td><td>10.0</td><td>1582.5</td><td>41.0</td><td>1583.0</td><td>25.0</td><td>1584.0</td><td>20.0</td><td>1585.0</td><td>14.0</td><td>1585.5</td><td>1.0</td><td>1587.5</td><td>2.0</td><td>1575.0</td><td>10.0</td><td>1574.0</td><td>4.0</td><td>1573.0</td><td>31.0</td><td>1571.0</td><td>5.0</td><td>1570.5</td><td>2.0</td><td>1570.0</td><td>104.0</td><td>1569.5</td><td>1.0</td><td>1567.0</td><td>25.0</td><td>1566.0</td><td>61.0</td><td>1565.5</td><td>26.0</td><td>1565.0</td><td>7.0</td><td>1564.0</td><td>202.0</td><td>1563.0</td><td>2.0</td><td>1562.5</td><td>2.0</td><td>1562.0</td><td>172.0</td></tr><tr><td>3497662</td><td>0.0</td><td>1576.0</td><td>2.0</td><td>1576.5</td><td>1.0</td><td>1577.0</td><td>10.0</td><td>1577.5</td><td>1.0</td><td>1578.0</td><td>3.0</td><td>1579.0</td><td>1.0</td><td>1579.5</td><td>8.0</td><td>1581.5</td><td>10.0</td><td>1582.0</td><td>10.0</td><td>1582.5</td><td>41.0</td><td>1583.0</td><td>25.0</td><td>1584.0</td><td>20.0</td><td>1585.0</td><td>14.0</td><td>1585.5</td><td>1.0</td><td>1587.5</td><td>2.0</td><td>1575.0</td><td>10.0</td><td>1574.0</td><td>4.0</td><td>1573.0</td><td>31.0</td><td>1571.0</td><td>5.0</td><td>1570.5</td><td>2.0</td><td>1570.0</td><td>104.0</td><td>1569.5</td><td>1.0</td><td>1567.0</td><td>25.0</td><td>1566.0</td><td>61.0</td><td>1565.5</td><td>26.0</td><td>1565.0</td><td>7.0</td><td>1564.0</td><td>202.0</td><td>1563.0</td><td>2.0</td><td>1562.5</td><td>2.0</td><td>1562.0</td><td>172.0</td></tr><tr><td>3497663</td><td>0.0</td><td>1576.0</td><td>3.0</td><td>1576.5</td><td>1.0</td><td>1577.0</td><td>10.0</td><td>1577.5</td><td>1.0</td><td>1578.0</td><td>3.0</td><td>1579.0</td><td>1.0</td><td>1579.5</td><td>8.0</td><td>1581.5</td><td>10.0</td><td>1582.0</td><td>10.0</td><td>1582.5</td><td>41.0</td><td>1583.0</td><td>25.0</td><td>1584.0</td><td>20.0</td><td>1585.0</td><td>14.0</td><td>1585.5</td><td>1.0</td><td>1587.5</td><td>2.0</td><td>1575.0</td><td>10.0</td><td>1574.0</td><td>4.0</td><td>1573.0</td><td>31.0</td><td>1571.0</td><td>5.0</td><td>1570.5</td><td>2.0</td><td>1570.0</td><td>104.0</td><td>1569.5</td><td>1.0</td><td>1567.0</td><td>25.0</td><td>1566.0</td><td>61.0</td><td>1565.5</td><td>26.0</td><td>1565.0</td><td>7.0</td><td>1564.0</td><td>202.0</td><td>1563.0</td><td>2.0</td><td>1562.5</td><td>2.0</td><td>1562.0</td><td>172.0</td></tr><tr><td>3497664</td><td>0.0</td><td>1576.0</td><td>3.0</td><td>1576.5</td><td>1.0</td><td>1577.0</td><td>10.0</td><td>1578.0</td><td>3.0</td><td>1579.0</td><td>1.0</td><td>1579.5</td><td>8.0</td><td>1581.5</td><td>10.0</td><td>1582.0</td><td>10.0</td><td>1582.5</td><td>41.0</td><td>1583.0</td><td>25.0</td><td>1584.0</td><td>20.0</td><td>1585.0</td><td>14.0</td><td>1585.5</td><td>1.0</td><td>1587.5</td><td>2.0</td><td>1588.0</td><td>20.0</td><td>1575.0</td><td>10.0</td><td>1574.0</td><td>4.0</td><td>1573.0</td><td>31.0</td><td>1571.0</td><td>5.0</td><td>1570.5</td><td>2.0</td><td>1570.0</td><td>104.0</td><td>1569.5</td><td>1.0</td><td>1567.0</td><td>25.0</td><td>1566.0</td><td>61.0</td><td>1565.5</td><td>26.0</td><td>1565.0</td><td>7.0</td><td>1564.0</td><td>202.0</td><td>1563.0</td><td>2.0</td><td>1562.5</td><td>2.0</td><td>1562.0</td><td>172.0</td></tr><tr><td>3497665</td><td>0.0</td><td>1576.0</td><td>2.0</td><td>1576.5</td><td>2.0</td><td>1577.0</td><td>10.0</td><td>1578.0</td><td>3.0</td><td>1579.0</td><td>1.0</td><td>1579.5</td><td>8.0</td><td>1581.5</td><td>10.0</td><td>1582.0</td><td>10.0</td><td>1582.5</td><td>41.0</td><td>1583.0</td><td>25.0</td><td>1584.0</td><td>20.0</td><td>1585.0</td><td>14.0</td><td>1585.5</td><td>1.0</td><td>1587.5</td><td>2.0</td><td>1588.0</td><td>20.0</td><td>1575.0</td><td>10.0</td><td>1574.0</td><td>4.0</td><td>1573.0</td><td>31.0</td><td>1571.0</td><td>5.0</td><td>1570.5</td><td>2.0</td><td>1570.0</td><td>104.0</td><td>1569.5</td><td>1.0</td><td>1567.0</td><td>25.0</td><td>1566.0</td><td>61.0</td><td>1565.5</td><td>26.0</td><td>1565.0</td><td>7.0</td><td>1564.0</td><td>202.0</td><td>1563.0</td><td>2.0</td><td>1562.5</td><td>2.0</td><td>1562.0</td><td>172.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3_497_666, 62)\n",
       "┌─────────┬──────┬──────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ time    ┆ y    ┆ askRate0 ┆ askSize0 ┆ … ┆ bidRate13 ┆ bidSize13 ┆ bidRate14 ┆ bidSize14 │\n",
       "│ ---     ┆ ---  ┆ ---      ┆ ---      ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ i64     ┆ f64  ┆ f64      ┆ f64      ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞═════════╪══════╪══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0       ┆ -0.5 ┆ 1619.5   ┆ 1.0      ┆ … ┆ 1601.0    ┆ 10.0      ┆ 1600.0    ┆ 13.0      │\n",
       "│ 1       ┆ -0.5 ┆ 1619.5   ┆ 1.0      ┆ … ┆ 1601.0    ┆ 10.0      ┆ 1600.0    ┆ 13.0      │\n",
       "│ 2       ┆ -0.5 ┆ 1619.5   ┆ 1.0      ┆ … ┆ 1601.0    ┆ 10.0      ┆ 1600.0    ┆ 13.0      │\n",
       "│ 3       ┆ -0.5 ┆ 1619.5   ┆ 1.0      ┆ … ┆ 1601.0    ┆ 10.0      ┆ 1600.0    ┆ 13.0      │\n",
       "│ 4       ┆ -0.5 ┆ 1619.5   ┆ 1.0      ┆ … ┆ 1601.0    ┆ 10.0      ┆ 1600.0    ┆ 13.0      │\n",
       "│ …       ┆ …    ┆ …        ┆ …        ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 3497661 ┆ 0.0  ┆ 1576.0   ┆ 3.0      ┆ … ┆ 1562.5    ┆ 2.0       ┆ 1562.0    ┆ 172.0     │\n",
       "│ 3497662 ┆ 0.0  ┆ 1576.0   ┆ 2.0      ┆ … ┆ 1562.5    ┆ 2.0       ┆ 1562.0    ┆ 172.0     │\n",
       "│ 3497663 ┆ 0.0  ┆ 1576.0   ┆ 3.0      ┆ … ┆ 1562.5    ┆ 2.0       ┆ 1562.0    ┆ 172.0     │\n",
       "│ 3497664 ┆ 0.0  ┆ 1576.0   ┆ 3.0      ┆ … ┆ 1562.5    ┆ 2.0       ┆ 1562.0    ┆ 172.0     │\n",
       "│ 3497665 ┆ 0.0  ┆ 1576.0   ┆ 2.0      ┆ … ┆ 1562.5    ┆ 2.0       ┆ 1562.0    ┆ 172.0     │\n",
       "└─────────┴──────┴──────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>value</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>3.497666e6</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>0.687398</td></tr><tr><td>&quot;std&quot;</td><td>0.334971</td></tr><tr><td>&quot;min&quot;</td><td>0.5</td></tr><tr><td>&quot;25%&quot;</td><td>0.5</td></tr><tr><td>&quot;50%&quot;</td><td>0.5</td></tr><tr><td>&quot;75%&quot;</td><td>1.0</td></tr><tr><td>&quot;max&quot;</td><td>9.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌────────────┬────────────┐\n",
       "│ statistic  ┆ value      │\n",
       "│ ---        ┆ ---        │\n",
       "│ str        ┆ f64        │\n",
       "╞════════════╪════════════╡\n",
       "│ count      ┆ 3.497666e6 │\n",
       "│ null_count ┆ 0.0        │\n",
       "│ mean       ┆ 0.687398   │\n",
       "│ std        ┆ 0.334971   │\n",
       "│ min        ┆ 0.5        │\n",
       "│ 25%        ┆ 0.5        │\n",
       "│ 50%        ┆ 0.5        │\n",
       "│ 75%        ┆ 1.0        │\n",
       "│ max        ┆ 9.0        │\n",
       "└────────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.with_columns((cs.contains(\"Rate0\") - pl.col(\"midprice\")) / 0.5).select(cs.contains(\"Rate0\"))[\"askRate0\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute order flow\n",
    "def order_flow(price_col: str, vol_col: str, side: str) -> pl.Expr:\n",
    "    price_diff = pl.col(price_col).diff(1)\n",
    "    vol_lag = pl.col(vol_col).shift(1)\n",
    "    \n",
    "    ge_case = pl.col(vol_col).shift(1).neg() if side == \"ask\" else pl.col(vol_col)\n",
    "    le_case = pl.col(vol_col).shift(1).neg() if side == \"bid\" else pl.col(vol_col)\n",
    "    eq_case = pl.col(vol_col).diff(1)\n",
    "    \n",
    "    return (\n",
    "        pl\n",
    "        .when(price_diff > 0).then(ge_case)\n",
    "        .when(price_diff < 0).then(le_case)\n",
    "        .otherwise(eq_case)\n",
    "    )\n",
    "\n",
    "# I checked that the order flow is correct, so dropping prices and volumes\n",
    "df_of = (\n",
    "    df\n",
    "    .with_columns((cs.contains(\"Rate\") | cs.contains(\"Size\")).fill_null(0))\n",
    "    .with_columns(\n",
    "        order_flow(f\"{side}Rate{l}\", f\"{side}Size{l}\", side).alias(f\"{side}OrderFlow{l}\") \n",
    "        for l in range(15)\n",
    "        for side in [\"bid\", \"ask\"]\n",
    "    )\n",
    "    .select(cs.by_name(cols) | cs.contains(\"OrderFlow\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(df_of, pn.aes(x=\"time\", y=\"askOrderFlow0\"))\n",
    "    + pn.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ticks = 10\n",
    "tick_size = 0.5\n",
    "\n",
    "(\n",
    "    df\n",
    "    .with_columns(bid_vol=pl.concat_list(cs.contains(\"bidSize\")).list.)\n",
    "    .select(\"bid_vol\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cumulative sum of volume\n",
    "(\n",
    "    df\n",
    "    .with_columns((cs.contains(\"Rate\") | cs.contains(\"Size\")).fill_null(0))\n",
    "    .with_columns(pl.cum_sum_horizontal(f\"bidSize{i}\" for i in range(15)))\n",
    "    .select([\"time\", \"cum_sum\"])\n",
    "    .with_columns(cum_sum=pl.concat_list(pl.col(\"cum_sum\").struct.unnest()))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise order flow\n",
    "window_size = 100\n",
    "min_periods = 5\n",
    "def standard_scaler(col, **kwargs) -> pl.Expr:\n",
    "    return (col - col.rolling_mean(**kwargs)) / (col.rolling_std(**kwargs) + 1e-8)\n",
    "\n",
    "def min_max_scaler(col, feature_range=(0, 1), **kwargs) -> pl.Expr:\n",
    "    range_min, range_max = feature_range\n",
    "    rolling_min = col.rolling_min(**kwargs)\n",
    "    rolling_max = col.rolling_max(**kwargs)\n",
    "    scaled = (col - rolling_min) / (rolling_max - rolling_min + 1e-8)\n",
    "    # Scale to the desired feature range\n",
    "    return scaled * (range_max - range_min) + range_min\n",
    "\n",
    "# df_of = df_of.with_columns(standard_scaler(cs.contains(\"OrderFlow\"), window_size=window_size, min_periods=min_periods))\n",
    "df_of = df_of.with_columns(min_max_scaler(cs.contains(\"OrderFlow\"), window_size=window_size, min_periods=min_periods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of[\"askOrderFlow0\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of[\"askOrderFlow0\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(df_of[-2000:], pn.aes(x=\"time\", y=\"askOrderFlow0\"))\n",
    "    + pn.geom_line()\n",
    "    + pn.geom_line(pn.aes(y=\"bidOrderFlow0\"), color=\"red\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(df, pn.aes(x=\"time\", y=\"midprice\"))\n",
    "    + pn.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(df, pn.aes(x=\"time\", y=\"y\"))\n",
    "    + pn.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "\n",
    "def normalise_exp(col_name: str, window_size: int) -> pl.Expr:\n",
    "    return (pl.col(col_name) - pl.col(col_name).rolling_mean(window_size)) / pl.col(col_name).rolling_std(window_size)\n",
    "\n",
    "norm_df = (\n",
    "    df\n",
    "    # Normalise volumes within each timestep wrt to total depth\n",
    "    .with_columns(cs.contains(\"Size\") / pl.col(\"total_depth\"))\n",
    "    # Normalise prices within each timestep wrt to midprice and spread\n",
    "    .with_columns((cs.contains(\"Rate\") - pl.col(\"midprice\")) / pl.col(\"spread\"))\n",
    "    # Normalise derived features across timesteps\n",
    "    .with_columns(normalise_exp(c, window_size) for c in derived_feat)\n",
    ")\n",
    "\n",
    "assert len(norm_df) - len(norm_df.drop_nulls(subset=derived_feat)) == window_size - 1\n",
    "norm_df = norm_df.drop_nulls(subset=derived_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "\n",
    "def normalise_exp(col_name: str, window_size: int) -> pl.Expr:\n",
    "    return (pl.col(col_name) - pl.col(col_name).rolling_mean(window_size)) / pl.col(col_name).rolling_std(window_size)\n",
    "\n",
    "norm_df = df.with_columns(\n",
    "    # Normalise prices within each timestep wrt to midprice and spread\n",
    "    (cs.contains(\"Rate\") - pl.col(\"midprice\")) / pl.col(\"spread\"),\n",
    "    # Normalise volumes within each timestep wrt to total depth\n",
    "    cs.contains(\"Size\") / pl.col(\"total_depth\"),\n",
    "    # Normalise derived features across timesteps\n",
    "    *[normalise_exp(c, window_size) for c in derived_feat],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    norm_df.with_columns(p=(pl.col(\"midprice\") != pl.col(\"midprice\").shift(1)).cum_sum()).select([\"time\", \"p\"])\n",
    "    # .group_by(\"p\").len().describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.group_by(\"p\").agg(pl.col(\"time\")).filter(pl.col(\"time\").list.len() > 500).with_columns(n_periods=pl.col(\"time\").list.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter((pl.col(\"time\") > 178225) & (pl.col(\"time\") < 178864))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df[\"spread\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "res = STL(df[\"midprice\"].to_numpy(), period=2).fit()\n",
    "res.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_values = acf(df[\"midprice\"], nlags=)\n",
    "lags = list(range(len(acf_values)))\n",
    "\n",
    "(\n",
    "    pn.ggplot(pl.DataFrame({'lags': lags, 'acf_values': acf_values}), pn.aes(x='lags', y='acf_values'))\n",
    "    + pn.geom_bar(stat='identity')\n",
    "    + pn.ggtitle('Autocorrelation Function')\n",
    "    + pn.xlab('Lags')\n",
    "    + pn.ylab('ACF Values')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    # Normalise prices within each timestep wrt to midprice and spread\n",
    "    (cs.contains(\"Rate\") - pl.col(\"midprice\")) / pl.col(\"spread\"),\n",
    "    # Normalise volumes within each timestep wrt to total depth\n",
    "    cs.contains(\"Size\") / pl.col(\"total_depth\"),\n",
    "    # Normalise derived features across timesteps\n",
    "    *[normalise_exp(c, window_size) for c in derived_feat],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df.filter(pl.col(\"midprice\").is_nan()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df[\"midprice\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(norm_df, pn.aes(\"time\", \"midprice\"))\n",
    "    + pn.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "\n",
    "def normalise_exp(col_name: str, window_size: int) -> pl.Expr:\n",
    "    return (pl.col(col_name) - pl.col(col_name).rolling_mean(window_size)) / pl.col(col_name).rolling_std(window_size)\n",
    "\n",
    "norm_df = df.with_columns([normalise_exp(c, window_size) for c in df.columns if c not in [\"time\", \"y\"]])\n",
    "assert len(norm_df) - len(norm_df.drop_nulls()) == window_size - 1\n",
    "\n",
    "norm_df = norm_df.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df[\"midprice\"].drop_nulls().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check target value is midprice(t+87) - midprice(t) clipped between -5 and 5\n",
    "assert len(\n",
    "    df.select([\"midprice\", \"y\"])\n",
    "    .with_columns(y_rec=(pl.col(\"midprice\").shift(-87) - pl.col(\"midprice\")).clip(-5, 5))\n",
    "    .with_columns(diff=pl.col(\"y\") - pl.col(\"y_rec\"))\n",
    "    .drop_nulls()\n",
    "    .filter(pl.col(\"diff\") != 0)\n",
    ") == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tick size\n",
    "exps = [\n",
    "    pl.col(f\"{side}Rate{i}\") - pl.col(f\"{side}Rate{i-1}\")\n",
    "    for i in range(1, 15)\n",
    "    for side in [\"ask\", \"bid\"]\n",
    "]\n",
    "\n",
    "tick_size = (\n",
    "    # select prices\n",
    "    df.select(cs.contains(\"Rate\"))\n",
    "    # run differences wrt previous level\n",
    "    .with_columns(*exps)\n",
    "    # get absolute values\n",
    "    .with_columns(pl.all().abs())\n",
    "    # get the minimum per row and then overall\n",
    "    .min_horizontal().min()\n",
    ")\n",
    "print(f\"{tick_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    ((pl.col(\"midprice\") - pl.col(f\"{side}Rate{i}\")) / tick_size).alias(f\"{side}Rate{i}_from_mid\")\n",
    "    for i in range(0, 15)\n",
    "    for side in [\"ask\", \"bid\"]\n",
    "]\n",
    "rel_df = (\n",
    "    df\n",
    "    # compute how many ticks away from midprice\n",
    "    .with_columns(*exps)\n",
    "    # convert spread as number of ticks\n",
    "    .with_columns(pl.col(\"spread\") / tick_size)\n",
    "    # select prices\n",
    "    .select(cs.by_name(default_cols) | cs.contains(\"_from_mid\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df[\"spread\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"askRate1\").is_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(df.with_columns(diff=pl.col(\"askRate0\") - pl.col(\"askRate1\")), pn.aes(\"time\", \"diff\"))\n",
    "    + pn.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(rel_df, pn.aes(x=\"time\", y=\"midprice\"))\n",
    "    + pn.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(rel_df, pn.aes(x=\"time\", y=\"y\"))\n",
    "    + pn.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(rel_df, pn.aes(x=\"spread\"))\n",
    "    + pn.geom_histogram(bins=20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Basic features\n",
    "# df = df.with_columns(\n",
    "#     midprice=(pl.col(\"askRate0\") + pl.col(\"bidRate0\")) / 2,\n",
    "#     spread=pl.col(\"askRate0\") - pl.col(\"bidRate0\"),\n",
    "#     # skew=pl.col(\"askSize0\").log() - pl.col(\"bidSize0\").log(),\n",
    "#     # total_ask_size=pl.sum_horizontal(cs.contains(\"askSize\")),\n",
    "#     # total_bid_size=pl.sum_horizontal(cs.contains(\"bidSize\")),\n",
    "# )\n",
    "\n",
    "# # # Volume-Weighted Average Price (VWAP)\n",
    "# # df = df.with_columns(\n",
    "# #     ask_vmap=pl.col('total_ask_size') / pl.sum_horizontal(pl.col(f'askRate{i}') * pl.col(f'askSize{i}') for i in range(15)),\n",
    "# #     bid_vmap=pl.col('total_bid_size') / pl.sum_horizontal(pl.col(f'bidRate{i}') * pl.col(f'bidSize{i}') for i in range(15)),\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = (\n",
    "    df[:200_000]\n",
    "    .select(cs.contains(\"Rate\") | cs.contains(\"Size\") | cs.contains(\"time\"))\n",
    "    .unpivot(index=\"time\")\n",
    "    .with_columns(\n",
    "        level=pl.col(\"variable\").str.extract(\"(\\d+)\").cast(pl.Int16),\n",
    "        side=pl.col(\"variable\").str.extract(\"([a-z]+)\"),\n",
    "        is_volume=pl.col(\"variable\").str.contains(\"Size\"),\n",
    "    )\n",
    "    .drop(\"variable\")\n",
    "    .pivot(index=[\"time\", \"level\", \"side\"], on=\"is_volume\", values=\"value\")\n",
    "    .rename({\"false\": \"price\", \"true\": \"volume\"})\n",
    "    .filter(pl.col(\"level\") < 10)\n",
    "    # .filter(pl.col(\"volume\") > 0)\n",
    "    # .pivot(index=[\"time\", \"level\"], on=[\"side\", \"is_volume\"], values=\"value\")\n",
    "    # .rename(\n",
    "    #     {\n",
    "    #         \"{\\\"ask\\\",false}\": \"ask_price\",\n",
    "    #         \"{\\\"ask\\\",true}\": \"ask_volume\",\n",
    "    #         \"{\\\"bid\\\",false}\": \"bid_price\",\n",
    "    #         \"{\\\"bid\\\",true}\": \"bid_volume\",\n",
    "    #     }\n",
    "    # )\n",
    ")\n",
    "pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.group_by([\"level\", \"side\"]).agg(pl.col(\"volume\").mean()).pivot(on=\"side\", index=\"level\").sort(\"level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     pn.ggplot(pdata.filter(pl.col(\"level\") < 5), pn.aes(\"time\", \"price\", alpha=\"volume\", colour=\"side\"))\n",
    "#     + pn.geom_point()\n",
    "#     + pn.scale_alpha_continuous(range=(0.01, 1), guide=None, limits=(80, None))\n",
    "#     + pn.scale_colour_manual(cmap)\n",
    "#     + pn.theme_bw()\n",
    "#     + pn.theme(legend_position=\"none\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "models = [\n",
    "    lgb.LGBMRegressor(random_state=0, verbosity=-1),\n",
    "    LinearRegression(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast import MLForecast\n",
    "from mlforecast.lag_transforms import ExpandingMean, RollingMean\n",
    "from mlforecast.target_transforms import Differences\n",
    "\n",
    "fcst = MLForecast(\n",
    "    models=models,\n",
    "    freq=1,\n",
    "    # lags=[7, 14],\n",
    "    # lag_transforms={\n",
    "    #     1: [ExpandingMean()],\n",
    "    #     7: [RollingMean(window_size=28)]\n",
    "    # },\n",
    "    # target_transforms=[],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regdata = (\n",
    "    df.select(cs.starts_with(\"ask\") | cs.starts_with(\"ask\") | cs.by_name([\"y\", \"time\", \"uid\"]))\n",
    "    .drop(\"ask_vmap\")\n",
    "    .to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst.fit(regdata, id_col=\"uid\", time_col=\"time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Step 1: Define indices for time-based splits\n",
    "n = len(regdata)\n",
    "train_end = int(n * 0.7)  # 70% for training\n",
    "val_start = int(n * 0.8)  # Skip the middle 10%\n",
    "val_end = n  # Last 20% for validation\n",
    "\n",
    "y = regdata[\"y\"].values\n",
    "X = regdata.drop(columns=[\"y\", \"uid\", \"time\"])\n",
    "\n",
    "# Step 2: Create the time-based splits\n",
    "X_train, y_train = X[:train_end], y[:train_end]\n",
    "X_val, y_val = X[val_start:val_end], y[val_start:val_end]\n",
    "\n",
    "# Step 3: Re-train the linear regression model on the new splits\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Step 5: Evaluate the model with updated splits\n",
    "r2_time_split = r2_score(y_val, y_pred)\n",
    "mse_time_split = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "r2_time_split, mse_time_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop unnecessary columns for simplicity in the baseline model\n",
    "features = ['spread', 'total_ask_size', 'total_bid_size', 'ask_vwap', 'bid_vwap']\n",
    "X = data.select(features)\n",
    "y = data['y']\n",
    "\n",
    "X.head(), y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove trading halts (order book does not change)\n",
    "# prev_len = len(df)\n",
    "# df = df.unique().sort(\"time\")\n",
    "# prev_len - len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a smaller sample (this is enough to have similar statistics to the original size)\n",
    "sdf = df.head(1_000_000 // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdf\n",
    "    .rename({\"askRate0\": \"ask_price\", \"bidRate0\": \"bid_price\", \"askSize0\": \"ask_vol\", \"bidSize0\": \"bid_vol\"})\n",
    "    # .with_columns(\n",
    "    #     ask_prices=pl.concat_list(cs.contains(\"askRate\")),\n",
    "    #     ask_prices=pl.concat_list(cs.contains(\"askSize\")),\n",
    "    #     bid_prices=pl.concat_list(cs.contains(\"bidRate\")),\n",
    "    # )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y\"].describe(), df[\"y\"].unique().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(df, pn.aes(\"time\"))\n",
    "    + pn.geom_line(pn.aes(y=\"askRate0\"), colour=\"red\")\n",
    "    + pn.geom_line(pn.aes(y=\"bidRate0\"), colour=\"green\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(df, pn.aes(\"time\", \"skew\"))\n",
    "    + pn.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"askRate0\", \"bidRate0\", \"y\"].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = (\n",
    "    df.select(cs.contains(\"Size\") | cs.contains(\"time\"))\n",
    "    .unpivot(index=\"time\")\n",
    "    .with_columns(level=pl.col(\"variable\").str.extract(\"(\\d+)\").cast(pl.Int16))\n",
    "    .with_columns(level=pl.when(pl.col(\"variable\").str.starts_with(\"ask\")).then(pl.col(\"level\")).otherwise(pl.col(\"level\").neg()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(pdata.filter(pl.col(\"time\") == 49), pn.aes(\"factor(level)\", \"value\"))\n",
    "    + pn.geom_bar(stat=\"identity\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(pdata.filter(pl.col(\"time\") == 50), pn.aes(\"factor(level)\", \"value\"))\n",
    "    + pn.geom_bar(stat=\"identity\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(pdata.filter(pl.col(\"time\") == 51), pn.aes(\"factor(level)\", \"value\"))\n",
    "    + pn.geom_bar(stat=\"identity\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
