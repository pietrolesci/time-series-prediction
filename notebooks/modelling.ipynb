{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('vegafusion')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import torch\n",
    "from lightning.fabric import Fabric\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from src.datamodule import DataloaderConfig, DataModule, collate_fn\n",
    "from src.dataset import LOBDataset, OrderFlowDataset\n",
    "from src.models.deeplob import DeepLOBConfig\n",
    "from src.models.deepvol import DeepVolConfig\n",
    "\n",
    "alt.data_transformers.enable(\"vegafusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = OrderFlowDataset(\"data/orderflow/train_memmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-12-20 18:29:16,493\u001b[0m][\u001b[34mdata\u001b[0m][\u001b[32mINFO\u001b[0m] - Train dataset loaded: len(self.train_ds)=2799999\u001b[0m\n",
      "[\u001b[36m2024-12-20 18:29:16,496\u001b[0m][\u001b[34mdata\u001b[0m][\u001b[32mINFO\u001b[0m] - Validation dataset loaded: len(self.val_ds)=250000\u001b[0m\n",
      "[\u001b[36m2024-12-20 18:29:16,498\u001b[0m][\u001b[34mdata\u001b[0m][\u001b[32mINFO\u001b[0m] - Test dataset loaded: len(self.test_ds)=297666\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dl_config = DataloaderConfig(batch_size=32, eval_batch_size=64, shuffle=True)\n",
    "dm = DataModule(\n",
    "    dl_config, \n",
    "    window_size=100, \n",
    "    num_levels=10, \n",
    "    train_data_path=\"data/orderflow/train_memmap\",\n",
    "    val_data_path=\"data/orderflow/val_memmap\",\n",
    "    test_data_path=\"data/orderflow/test_memmap\",\n",
    "    data_repr=\"orderflow\",\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pl487/.local/share/uv/python/cpython-3.11.10-linux-x86_64-gnu/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n",
      "/home/pl487/.local/share/uv/python/cpython-3.11.10-linux-x86_64-gnu/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 100, 20]), torch.Size([64, 1]), torch.Size([64]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = next(iter(dm.test_dataloader()))\n",
    "b[\"X\"].shape, b[\"y\"].shape, b[\"idx\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DeepVolConfig(num_targets=dm.num_targets, num_levels=dm.num_levels)\n",
    "model = config.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100, 20])\n",
      "torch.Size([64, 1, 100, 20])\n",
      "torch.Size([64, 32, 100, 10])\n",
      "torch.Size([64, 32, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pl487/time-series-prediction/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:549: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1036.)\n",
      "  return F.conv2d(\n"
     ]
    }
   ],
   "source": [
    "x = b[\"X\"]\n",
    "print(x.shape)\n",
    "x = x.unsqueeze(1)\n",
    "print(x.shape)\n",
    "x = model.conv2(x)\n",
    "print(x.shape)\n",
    "x = model.conv3(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 100, 1])\n",
      "torch.Size([64, 64, 100, 1])\n",
      "torch.Size([64, 64, 100, 1])\n",
      "torch.Size([64, 192, 100, 1])\n",
      "torch.Size([64, 100, 192])\n"
     ]
    }
   ],
   "source": [
    "x_inp1 = model.inp1(x)\n",
    "print(x_inp1.shape)\n",
    "x_inp2 = model.inp2(x)\n",
    "print(x_inp2.shape)\n",
    "x_inp3 = model.inp3(x)\n",
    "print(x_inp3.shape)\n",
    "\n",
    "x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "print(x.shape)\n",
    "\n",
    "x = x.squeeze(-1).permute(0, 2, 1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100, 64])\n",
      "torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "x, _ = model.lstm(x)\n",
    "print(x.shape)\n",
    "\n",
    "x = x[:, -1, :]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 7])\n"
     ]
    }
   ],
   "source": [
    "x = model.fc(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, [0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1183, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.mse_loss(x[:, [0]], b[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = torch.tensor([[1, 2, 3], [1, 2, 3]]).float(), torch.tensor([[1, 2, 4], [1, 2, 5]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = (a - b)**2\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.mse_loss(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(err / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read L2 data\n",
    "df = pl.read_parquet(\"data/data.parquet\")\n",
    "\n",
    "# # Assuming that order reflects time\n",
    "# df = df.with_row_index(name=\"time\").with_columns(pl.col(\"time\").cast(pl.Int64))\n",
    "\n",
    "# Rescale prices by 1000 (so that they are around 1)\n",
    "df = df.with_columns(cs.contains(\"Rate\") / 1000, cs.contains(\"Size\").log())\n",
    "\n",
    "# Fill nulls with 0\n",
    "df = df.with_columns((cs.contains(\"Rate\") | cs.contains(\"Size\")).fill_null(0))\n",
    "\n",
    "# Midprice\n",
    "df = df.with_columns(\n",
    "    midprice=(pl.col(\"askRate0\") + pl.col(\"bidRate0\")) / 2,\n",
    "    spread=pl.col(\"askRate0\") - pl.col(\"bidRate0\"),\n",
    ")\n",
    "\n",
    "# Reorder cols\n",
    "cols = [\"y\", \"midprice\", \"spread\"]\n",
    "for i in range(15):\n",
    "    for side in [\"ask\", \"bid\"]:\n",
    "        cols += [f\"{side}Rate{i}\", f\"{side}Size{i}\"]\n",
    "\n",
    "df = df.select(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df) - 3_200_000) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "150_000 / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(df) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "num_cycles = 10\n",
    "num_training_steps = 50000 * 2\n",
    "num_warmup_steps = 2000\n",
    "\n",
    "def lr_lambda(current_step: int) -> float:\n",
    "    if current_step < num_warmup_steps:\n",
    "        return float(current_step) / float(max(1, num_warmup_steps))\n",
    "    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
    "\n",
    "def get_cosine_with_hard_restarts_schedule_with_warmup_lr_lambda(current_step: int) -> float:\n",
    "    if current_step < num_warmup_steps:\n",
    "        return float(current_step) / float(max(1, num_warmup_steps))\n",
    "    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "    if progress >= 1.0:\n",
    "        return 0.0\n",
    "    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * ((float(num_cycles) * progress) % 1.0))))\n",
    "\n",
    "\n",
    "lrs = [get_cosine_with_hard_restarts_schedule_with_warmup_lr_lambda(i) for i in range(num_training_steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame(lrs, schema=[\"lr\"]).with_row_index(name=\"step\").plot.line(\"step\", \"lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(cs.contains(\"Rate\") - pl.col(\"midprice\").shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    pl.col(f\"{side}Rate{i}\") - pl.col(f\"{side}Rate{i-1}\")\n",
    "    for i in range(1, 15)\n",
    "    for side in [\"ask\", \"bid\"]\n",
    "]\n",
    "exps.append(cs.contains(\"Rate0\") - pl.col(\"midprice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.with_columns(*exps)\n",
    "    # .filter(pl.any_horizontal(cs.contains(\"bidRate\") < -0.001))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/pl487/time-series-prediction/data/predictions/deeplob-reg-15_2024-12-11T16-00-39_model_train_1_val.parquet\"\n",
    "df = pl.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pred\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "path = \"/home/pl487/time-series-prediction/outputs/model_train/deeplob-reg-15_2024-12-13T15-53-48/predictions/val_preds_test.tsv\"\n",
    "df = pl.read_csv(path, separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .filter(pl.col(\"step\") == pl.col(\"step\").max())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(df[\"y\"], df[\"preds\"]), mean_squared_error(df[\"y\"], df[\"preds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    r2=1 - ((pl.col(\"y\") - pl.col(\"preds\")).pow(2).sum() / (pl.col(\"y\") - pl.col(\"y\").mean()).pow(2).sum())\n",
    ")[\"r2\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(diff=pl.col(\"pred\") - pl.col(\"y\"))[\"diff\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * 4 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_classification = False\n",
    "window_size = 100\n",
    "ds = LOBDataset(\"data/train_memmap.npy\", is_classification=is_classification, use_prev_y=False, window_size=window_size)\n",
    "dl = DataLoader(ds, batch_size=64, collate_fn=lambda x: collate_fn(x, max_len=window_size), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0][\"X\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))\n",
    "x, y = batch[\"X\"], batch[\"y\"]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DeepLOBConfig(is_classification=is_classification)\n",
    "model = config.get_model()\n",
    "preds = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = x.unsqueeze(1)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.conv1(h)\n",
    "h = model.conv2(h)\n",
    "h = model.conv3(h)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.inp1(h).shape, model.inp2(h).shape, model.inp3(h).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = torch.cat([model.inp1(h), model.inp2(h), model.inp3(h)], dim=1)\n",
    "hc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = hc.squeeze(-1)\n",
    "hc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = hc.permute(0, 2, 1)\n",
    "hc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl, hh = model.lstm(hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(\n",
    "    [[1, 2, 3, 4], \n",
    "     [5, 6, 7, 8]], \n",
    "    dtype=torch.float32,\n",
    ")\n",
    "h = x.unsqueeze(0).unsqueeze(0)\n",
    "x.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(1, 2, kernel_size=(1, 2), stride=(1, 2), bias=True)\n",
    "conv1.weight = torch.nn.Parameter(torch.ones_like(conv1.weight))\n",
    "conv1.bias = torch.nn.Parameter(torch.zeros_like(conv1.bias) + 10.)\n",
    "h1 = conv1(h)\n",
    "h1.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = torch.nn.Conv2d(2, 2, kernel_size=(4, 1), padding=\"same\")\n",
    "conv2.weight = torch.nn.Parameter(torch.ones_like(conv2.weight))\n",
    "conv2.bias = torch.nn.Parameter(torch.zeros_like(conv2.bias) - 10.)\n",
    "h2 = conv2(h1)\n",
    "h2.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = model.conv1[0](x)\n",
    "h2 = model.conv1[1](h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1.shape, h2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch[\"X\"]\n",
    " \n",
    "# Add channel dimention\n",
    "# x: batch_size, n_channels, seq_len, num_levels * 4\n",
    "x = x.unsqueeze(1)\n",
    "\n",
    "# Convolution blocks\n",
    "# x: batch_size, n_channels, seq_len, num_levels * 2\n",
    "x = model.conv1(x)\n",
    "x = model.conv2(x)\n",
    "x = model.conv3(x)\n",
    "\n",
    "# Inception blocks\n",
    "# batch_size, incep_out_channels, seq_len, 1\n",
    "x_inp1 = model.inp1(x)\n",
    "x_inp2 = model.inp2(x)\n",
    "x_inp3 = model.inp3(x)\n",
    "\n",
    "# Concatenate inception blocks\n",
    "# batch_size, incep_out_channels * 3, seq_len, 1\n",
    "x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "\n",
    "x = x.squeeze(-1).permute(0, 2, 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = model.pico(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.fc(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.squeeze(-1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = batch[\"X\"], batch[\"y\"]\n",
    "preds = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~(y <= -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = (preds[mask] - y[mask])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(*{\"a\": [1, 2], \"b\": [3, 4]}.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = batch[\"y\"]\n",
    "\n",
    "torch.nn.functional.mse_loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = torch.nn.Linear(192, 1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DeepLOBConfig(is_classification=True)\n",
    "model = config.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = batch[\"X\"], batch[\"y\"]\n",
    "preds = model.forward(x)\n",
    "loss = torch.nn.functional.cross_entropy(preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch._tensor import Tensor\n",
    "\n",
    "\n",
    "def collate_fn(batch) -> tuple[Tensor, Tensor]:\n",
    "    print(batch[0])\n",
    "    # Find the maximum length in the batch\n",
    "    max_len = max(item[\"X\"].shape[0] for item in batch)\n",
    "    \n",
    "    # Pad each instance to the maximum length\n",
    "    padded_batch = []\n",
    "    for item in batch:\n",
    "        X = item[\"X\"]\n",
    "        pad_size = max_len - X.shape[0]\n",
    "        if pad_size > 0:\n",
    "            X = torch.nn.functional.pad(X, (0, 0, pad_size, 0), \"constant\", 0)\n",
    "        \n",
    "        # pad the past such that the most recent observation is at the end\n",
    "        padded_batch.append(X)\n",
    "    \n",
    "    # Stack the padded instances\n",
    "    X_batch = torch.stack(padded_batch)\n",
    "    y_batch = torch.stack([item[\"y\"] for item in batch])\n",
    "    \n",
    "    return X_batch, y_batch\n",
    "\n",
    "dl = DataLoader(dataset, batch_size=32, collate_fn=collate_fn, shuffle=False)\n",
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.deeplob import DeepLOB\n",
    "\n",
    "model = DeepLOB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.mse_loss(model(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.module import RunningStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{RunningStage.TRAIN}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [dataset[i] for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(item[\"X\"].shape[0] for item in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = batch[1][\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_size = max_len - item.shape[0]\n",
    "\n",
    "torch.nn.functional.pad(item, (0, 0, pad_size, 0), mode=\"constant\", value=0.)[-2] == item[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOBDataset(Dataset):\n",
    "    def __init__(self, df, window_size: int = 100, use_prev_y: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.use_prev_y = use_prev_y\n",
    "\n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        if index >= len(self.df):\n",
    "            raise IndexError(\"Index out of bounds\")\n",
    "        data = self.df[max(0, index - self.window_size) : index + 1]\n",
    "        y = data[\"y\"].to_numpy()\n",
    "        X = data.drop(\"y\").to_numpy()\n",
    "        out = {\"X\": X, \"y\": y[-1]}\n",
    "        if self.use_prev_y:\n",
    "            out[\"prev_y\"] = y[:-1]\n",
    "        return out\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    @property\n",
    "    def num_levels(self) -> int:\n",
    "        return (self.df.width - 1) // 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict[\"train\"][\"y\"].value_counts().sort(\"y\").plot.bar(x=\"y:N\", y=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_to_class(y: float) -> int:\n",
    "    return int((y + 5) / 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.arange(-5, 5.25, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((c + 5) / 0.25).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.arange(-5, 5.25, 0.25)\n",
    "((c + 5) / 0.25).int() * 0.25 - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in ds_dict.items():\n",
    "    v.write_parquet(f\"data/{k}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOBDataset(Dataset):\n",
    "    def __init__(self, df, window_size: int = 100) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "    \n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        if index >= len(self.df):\n",
    "            raise IndexError(\"Index out of bounds\")\n",
    "        data = self.df[max(0, index - self.window_size) : index + 1]\n",
    "        y = data[\"y\"].to_numpy()\n",
    "        X = data.drop(\"y\").to_numpy()\n",
    "        return {\"X\": X, \"y\": y[-1], \"prev_y\": y[:-1]}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    @property\n",
    "    def num_levels(self) -> int:\n",
    "        return (len(self.df.width) - 1) // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = LOBDataset(ds_dict[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0][\"X\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[8][\"X\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(train_ds, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"prev_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = LOBDataset(df)\n",
    "dl = DataLoader(ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "fabric = Fabric(accelerator=\"gpu\")\n",
    "\n",
    "model = DeepLOB(ds.num_levels)\n",
    "# model.compile()\n",
    "\n",
    "model = fabric.setup_module(model)\n",
    "dl = fabric.setup_dataloaders(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in trange(num_epochs, desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(dl, desc=\"Batch\", leave=False):\n",
    "        X, y = batch\n",
    "        if X.shape[1] < ds.window_size:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        fabric.backward(loss)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dl)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLOB(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (\n",
    "    torch.tensor(batch.drop(\"y\").to_numpy(), dtype=torch.float32)\n",
    "    .unsqueeze(0)\n",
    "    .repeat(2, 1, 1)\n",
    "    .unsqueeze(1)\n",
    ")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.conv1(X)  # batch_size, n_channels, seq_len, num_levels * 2\n",
    "x = model.conv2(x)\n",
    "x = model.conv3(x)\n",
    "\n",
    "x_inp1 = model.inp1(x)\n",
    "x_inp2 = model.inp2(x)\n",
    "x_inp3 = model.inp3(x)\n",
    "\n",
    "xc = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "# print(xc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x.permute(0, 2, 1, 3)\n",
    "x1 = x1.reshape((-1, x1.shape[1], x1.shape[2]))\n",
    "x2 = x.squeeze(-1).permute(0, 2, 1)\n",
    "x1.shape, x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3, _ = model.lstm(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3.shape, x3[:, -1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 100\n",
    "df = df.with_columns(\n",
    "    askRate0_norm=(\n",
    "        (pl.col(\"askRate0\") - pl.col(\"askRate0\").rolling_mean(window)) \n",
    "        / pl.col(\"askRate0\").rolling_std(window)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(cs.contains(\"askRate0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(0.7 * len(df)), int(0.2 * len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[: 2_500_000]\n",
    "test_df = df[-700_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOBDataset(Dataset):\n",
    "    def __init__(self, df: pl.DataFrame, window_size: int = 100) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df.select(cs.contains(\"Rate\") | cs.contains(\"Size\") | cs.contains(\"y\"))\n",
    "        self.window_size = window_size\n",
    "    \n",
    "    def __getitem__(self, index) -> torch.Tensor:\n",
    "        data = self.df[max(0, index - self.window_size) : index + 1]\n",
    "        y = data[\"y\"].to_numpy()\n",
    "        X = data.drop(\"y\").to_numpy()\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    @property\n",
    "    def num_levels(self) -> int:\n",
    "        return (self.df.width - 1) // 4\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = LOBDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLOB(ds.num_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X.transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
